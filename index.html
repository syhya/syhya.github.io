<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.151.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Yue Shui Blog</title><meta name=keywords content="Blog,Portfolio,PaperMod"><meta name=description content="ExampleSite description"><meta name=author content="Yue Shui"><link rel=canonical href=https://syhya.github.io/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.9271b00776af10d7feb512a59a411af859df11a64bb143b10ab1170a4e8da23f.css integrity="sha256-knGwB3avENf+tRKlmkEa+FnfEaZLsUOxCrEXCk6Noj8=" rel="preload stylesheet" as=style><link rel=icon href=https://syhya.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://syhya.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://syhya.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://syhya.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://syhya.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/json href=https://syhya.github.io/index.json><link rel=alternate hreflang=en href=https://syhya.github.io/><link rel=alternate hreflang=zh href=https://syhya.github.io/zh/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><script>window.MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-SZ2660B91F"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-SZ2660B91F")}</script><meta property="og:url" content="https://syhya.github.io/"><meta property="og:site_name" content="Yue Shui Blog"><meta property="og:title" content="Yue Shui Blog"><meta property="og:description" content="ExampleSite description"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta property="og:image" content="https://syhya.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://syhya.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Yue Shui Blog"><meta name=twitter:description content="ExampleSite description"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Yue Shui Blog","url":"https://syhya.github.io/","description":"ExampleSite description","logo":"https://syhya.github.io/%3Clink%20/%20abs%20url%3E","sameAs":["https://www.linkedin.com/in/yue-shui/","https://github.com/syhya","mailto:syhya925666582@gmail.com"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://syhya.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://syhya.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://syhya.github.io/zh/ title=ç®€ä½“ä¸­æ–‡ aria-label=ç®€ä½“ä¸­æ–‡>Zh</a></li></ul></div></div><ul id=menu><li><a href=https://syhya.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://syhya.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://syhya.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>ðŸ‘‹ Welcome to Yue&rsquo;s blog</h1></header><div class=entry-content>Hi, this is Yue Shui. Iâ€™m currently working on LLM algorithms, with a focus on Agentic RL. My past experience includes researching and applying LLMs in fields such as finance, audit, and code generation. This blog is where I document and share insights from my work and learning journey. The grammar mistakes in the posts might give you a hint about ChatGPTâ€™s involvement ðŸ˜‰â€”let me know if you spot any! My interests include model training, RAG, and LLM Agent. Feel free to connect!</div><footer class=entry-footer><div class=social-icons><a href=https://www.linkedin.com/in/yue-shui/ target=_blank rel="noopener noreferrer me" title=Linkedin><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg>
</a><a href=https://github.com/syhya target=_blank rel="noopener noreferrer me" title=Github><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a href=mailto:syhya925666582@gmail.com target=_blank rel="noopener noreferrer me" title=Email><svg viewBox="0 0 24 21" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></footer></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Agentic RL</h2></header><div class=entry-content><p>As Large Language Models (LLMs) achieve breakthroughs in natural language processing, their applications continue to expand. However, they also exhibit limitations such as knowledge cutoffs, hallucinations, and deficiencies in complex computation and logical reasoning. To address these challenges, Agentic RL, which combines agents with Reinforcement Learning (RL), is emerging as a key research direction.
Agentic RL enables LLMs to possess capabilities like autonomous planning, decision-making, tool use, and environmental interaction by creating a closed-loop interaction with the external world (e.g., search engines, code interpreters, databases, browsers) and continuously optimizing through reward signals. In practical applications, it not only understands requirements and plans autonomously but also constantly corrects and optimizes within an execution-feedback loop.
...</p></div><footer class=entry-footer><span title='2025-09-30 12:00:00 +0800 +0800'>Created:&nbsp;2025-09-30</span>&nbsp;Â·&nbsp;Updated:&nbsp;2025-09-30&nbsp;Â·&nbsp;24 min&nbsp;Â·&nbsp;5072 words&nbsp;Â·&nbsp;Yue Shui</footer><a class=entry-link aria-label="post link to Agentic RL" href=https://syhya.github.io/posts/2025-09-30-agentic-rl/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>gpt-oss & GPT-5</h2></header><div class=entry-content><p>In August 2025, the AI field witnessed a period of intensive releases from OpenAI. Following GPT-2 (OpenAI, 2019) in 2019, OpenAI has once again contributed to the open-source community with its first open-weight large language model series, gpt-oss (OpenAI, 2025), available in 120B and 20B sizes. Shortly after, the highly anticipated next-generation flagship model, GPT-5 (OpenAI, 2025), was also officially launched. This series of releases not only marks a new high for open-source models in reasoning and agent capabilities but also reveals OpenAIâ€™s latest advancements in model architecture, training methodologies, and safety alignment.
...</p></div><footer class=entry-footer><span title='2025-08-24 12:00:00 +0800 +0800'>Created:&nbsp;2025-08-24</span>&nbsp;Â·&nbsp;Updated:&nbsp;2025-08-24&nbsp;Â·&nbsp;12 min&nbsp;Â·&nbsp;2541 words&nbsp;Â·&nbsp;Yue Shui</footer><a class=entry-link aria-label="post link to gpt-oss & GPT-5" href=https://syhya.github.io/posts/2025-08-24-gpt5/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Large Language Model Inference</h2></header><div class=entry-content><p>In recent years, Large Language Models (LLMs) have achieved revolutionary breakthroughs in fields such as natural language processing, code generation, and even multimodal interaction. However, the powerful capabilities of these models come at the cost of enormous computational and memory overhead, especially during the inference stage. Efficiently deploying and running these models, which have billions or even trillions of parameters, has become a core challenge in scaling LLM technology for real-world applications.
...</p></div><footer class=entry-footer><span title='2025-06-29 12:00:00 +0800 +0800'>Created:&nbsp;2025-06-29</span>&nbsp;Â·&nbsp;Updated:&nbsp;2025-06-29&nbsp;Â·&nbsp;43 min&nbsp;Â·&nbsp;9025 words&nbsp;Â·&nbsp;Yue Shui</footer><a class=entry-link aria-label="post link to Large Language Model Inference" href=https://syhya.github.io/posts/2025-06-29-llm-inference/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>vLLM: High-Throughput, Memory-Efficient LLM Serving</h2></header><div class=entry-content><p>As the parameters of Large Language Models (LLMs) continue to grow, deploying and serving these models presents significant challenges. vLLM is an open-source library designed for fast, convenient, and cost-effective LLM inference and online serving. Its core lies in the PagedAttention algorithm, which efficiently manages the KV Cache in the attention mechanism.
Evaluation Metrics To evaluate the performance of LLM inference and serving engines, we primarily focus on the following metrics:
...</p></div><footer class=entry-footer><span title='2025-05-17 10:00:00 +0800 +0800'>Created:&nbsp;2025-05-17</span>&nbsp;Â·&nbsp;Updated:&nbsp;2025-05-17&nbsp;Â·&nbsp;20 min&nbsp;Â·&nbsp;4204 words&nbsp;Â·&nbsp;Yue Shui</footer><a class=entry-link aria-label="post link to vLLM: High-Throughput, Memory-Efficient LLM Serving" href=https://syhya.github.io/posts/2025-05-17-vllm/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Multimodal Large Language Models</h2></header><div class=entry-content><p>Humans interact with the world through multiple senses (vision, hearing, touch, etc.), with each sensory channel offering unique advantages in representing and communicating specific concepts. This multimodal interaction fosters our deep understanding of the world. One of the core goals in the field of artificial intelligence is to develop general-purpose assistants that can effectively follow multimodal instructions (such as visual and linguistic ones), enabling them to perform various real-world tasks like humans. In recent years, with the release of models like GPT-4o (OpenAI, 2024), Gemini 2.5 Pro (DeepMind, 2025), and o3/o4-mini (OpenAI, 2025), Multimodal Large Language Models (MLLMs) have made significant progress. They can not only understand information from multiple modalities like images, videos, and audio but also perform complex reasoning and generation.
...</p></div><footer class=entry-footer><span title='2025-05-04 12:00:00 +0800 +0800'>Created:&nbsp;2025-05-04</span>&nbsp;Â·&nbsp;Updated:&nbsp;2025-05-04&nbsp;Â·&nbsp;48 min&nbsp;Â·&nbsp;10182 words&nbsp;Â·&nbsp;Yue Shui</footer><a class=entry-link aria-label="post link to Multimodal Large Language Models" href=https://syhya.github.io/posts/2025-05-04-multimodal-llm/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://syhya.github.io/page/2/>Next&nbsp;&nbsp;Â»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://syhya.github.io/>Yue Shui Blog</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>