<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Self-Evolving Agents | Yue Shui Blog</title><meta name=keywords content="Agent Evolve,AlphaEvolve,OpenEvolve,AI for Science"><meta name=description content="A structural shift is underway in AI: the core capability of agents is moving from one-shot answer generation to continually producing verifiable, self-improving results in closed-loop systems. A representative milestone is DeepMind&rsquo;s release of AlphaEvolve, an LLM-driven evolutionary coding agent that has delivered breakthroughs in mathematics, algorithm design, and engineering optimization, in several cases improving upon best-known human-designed baselines. Under this paradigm, the division of labor between humans and agents is clearly reconfigured:"><meta name=author content="Yue Shui"><link rel=canonical href=https://syhya.github.io/posts/2026-02-20-self-evolving-agents/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.9271b00776af10d7feb512a59a411af859df11a64bb143b10ab1170a4e8da23f.css integrity="sha256-knGwB3avENf+tRKlmkEa+FnfEaZLsUOxCrEXCk6Noj8=" rel="preload stylesheet" as=style><link rel=icon href=https://syhya.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://syhya.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://syhya.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://syhya.github.io/apple-touch-icon.png><link rel=mask-icon href=https://syhya.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://syhya.github.io/posts/2026-02-20-self-evolving-agents/><link rel=alternate hreflang=zh href=https://syhya.github.io/zh/posts/2026-02-20-self-evolving-agents/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><script>window.MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-SZ2660B91F"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-SZ2660B91F")}</script><meta property="og:url" content="https://syhya.github.io/posts/2026-02-20-self-evolving-agents/"><meta property="og:site_name" content="Yue Shui Blog"><meta property="og:title" content="Self-Evolving Agents"><meta property="og:description" content="A structural shift is underway in AI: the core capability of agents is moving from one-shot answer generation to continually producing verifiable, self-improving results in closed-loop systems. A representative milestone is DeepMind’s release of AlphaEvolve, an LLM-driven evolutionary coding agent that has delivered breakthroughs in mathematics, algorithm design, and engineering optimization, in several cases improving upon best-known human-designed baselines. Under this paradigm, the division of labor between humans and agents is clearly reconfigured:"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-20T12:00:00+08:00"><meta property="article:modified_time" content="2026-02-20T12:00:00+08:00"><meta property="article:tag" content="Agent Evolve"><meta property="article:tag" content="AlphaEvolve"><meta property="article:tag" content="OpenEvolve"><meta property="article:tag" content="AI for Science"><meta name=twitter:card content="summary"><meta name=twitter:title content="Self-Evolving Agents"><meta name=twitter:description content="A structural shift is underway in AI: the core capability of agents is moving from one-shot answer generation to continually producing verifiable, self-improving results in closed-loop systems. A representative milestone is DeepMind&rsquo;s release of AlphaEvolve, an LLM-driven evolutionary coding agent that has delivered breakthroughs in mathematics, algorithm design, and engineering optimization, in several cases improving upon best-known human-designed baselines. Under this paradigm, the division of labor between humans and agents is clearly reconfigured:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://syhya.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Self-Evolving Agents","item":"https://syhya.github.io/posts/2026-02-20-self-evolving-agents/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Self-Evolving Agents","name":"Self-Evolving Agents","description":"A structural shift is underway in AI: the core capability of agents is moving from one-shot answer generation to continually producing verifiable, self-improving results in closed-loop systems. A representative milestone is DeepMind\u0026rsquo;s release of AlphaEvolve, an LLM-driven evolutionary coding agent that has delivered breakthroughs in mathematics, algorithm design, and engineering optimization, in several cases improving upon best-known human-designed baselines. Under this paradigm, the division of labor between humans and agents is clearly reconfigured:\n","keywords":["Agent Evolve","AlphaEvolve","OpenEvolve","AI for Science"],"articleBody":"A structural shift is underway in AI: the core capability of agents is moving from one-shot answer generation to continually producing verifiable, self-improving results in closed-loop systems. A representative milestone is DeepMind’s release of AlphaEvolve, an LLM-driven evolutionary coding agent that has delivered breakthroughs in mathematics, algorithm design, and engineering optimization, in several cases improving upon best-known human-designed baselines. Under this paradigm, the division of labor between humans and agents is clearly reconfigured:\nHumans are responsible for defining the What — setting evaluation criteria, providing initial candidate solutions, and injecting essential background knowledge as context into the model. Agents are responsible for figuring out the How — autonomously searching for and discovering better structures and algorithmic implementations by generating code and invoking external tools. Fig. 1. AlphaEvolve high-level overview. (Image source: Novikov et al., 2025)\nFunSearch Many LLM workflows rely on prompt engineering to elicit the desired output in a single pass, with the quality of the results largely determined by the model’s capabilities and the effectiveness of the prompt design. While highly effective for tasks like Q\u0026A and summarization, this approach has limitations in scenarios requiring the exploration of a search space or finding solutions that surpass the current state-of-the-art (SOTA). FunSearch (Romera-Paredes et al., 2024) emphasizes an iterative closed-loop approach, allowing the model to repeatedly generate, evaluate, and refine programs in an external environment.\nFig. 2. The overview of FunSearch. (Image source: Romera-Paredes et al., 2024)\nFunSearch is a stateful iterative closed loop:\n$$\\text{Specification} \\rightarrow \\text{Program Generation} \\rightarrow \\text{Evaluation} \\rightarrow \\text{Program Database Update} \\rightarrow \\text{Next Iteration}$$This presents three fundamental differences from the traditional single-pass generation paradigm:\nExternally Verifiable: Evaluation scores come from real executors (code execution, mathematical verification, performance testing). Cumulative Improvement: Each iteration builds on the best solutions so far, often yielding consistent gains over time. Governable: Sandbox execution, approval mechanisms, and rule constraints can be embedded into the loop, ensuring safety and controllability. AlphaEvolve AlphaEvolve (Novikov et al., 2025) is DeepMind’s next-generation evolutionary coding agent. Its core architecture orchestrates a closed-loop pipeline: LLMs generate and modify candidate programs, evaluators provide task-specific performance signals, and an evolutionary algorithm performs selection and mutation based on those signals—iteratively optimizing within the program space.\nFig. 3. The overall view of the AlphaEvolve discovery process. (Image source: Novikov et al., 2025)\nCompared to its predecessor FunSearch, which primarily focused on single-function optimization, AlphaEvolve expands the search space to entire codebases spanning multiple functions and components. Leveraging the long-context reasoning capabilities of SOTA LLMs, AlphaEvolve significantly enlarges the searchable program space, thereby raising the performance ceiling for complex algorithm discovery tasks.\nFeature FunSearch AlphaEvolve Scope evolves single function evolves entire code file Size evolves up to 10-20 lines of code evolves up to hundreds of lines of code Language evolves code in Python evolves any language Evaluation needs fast evaluation (≤ 20min on 1 CPU) can evaluate for hours, in parallel, on accelerators LLM Samples millions of LLM samples used thousands of LLM samples suffice LLM Type small LLMs used; no benefit from larger benefits from SOTA LLMs Prompt Context minimal context (only previous solutions) rich context and feedback in prompts Objective optimizes single metric can simultaneously optimize multiple metrics OpenEvolve OpenEvolve provides a high-quality open-source engineering implementation of AlphaEvolve, fully realizing its four core modules:\nFig. 4. The OpenEvolve architecture: showing the integration of LLMs, MAP-Elites population database, cascade evaluator, and evolution controller. (Image source: OpenEvolve)\nPrompt Sampler: Samples previously discovered solutions from the program database to construct rich context prompts. It includes not only the current best solution but also diverse sub-optimal alternatives as inspiration, preventing the LLM from falling into a single mode. Combined with a meta prompting mechanism, the LLM is used not only to generate answers but also to co-evolve the instructions and context themselves, thereby improving overall reasoning quality.\nLLM Ensemble: coordinates small and large models working synergistically—for example, a high-throughput smaller model handles broad exploration (increasing the rate of candidate generation), while a higher-reasoning large model focuses on occasional, high-quality rewrites. This ensemble strategy balances exploration and exploitation.\nEvaluator Pool: supports deterministic tests, cascaded statistical hypothesis testing, LLM-assisted feedback signals, and parallelized evaluation to improve throughput and efficiency. Evaluation results guide subsequent LLM generations, enabling continuous hill-climbing driven by error signals.\nProgram Database: maintains a population of solutions using MAP-Elites (Mouret \u0026 Clune, 2015) and an island-based population model. MAP-Elites maps the solution space onto a user-defined multidimensional feature grid, retaining the highest-fitness individual in each cell—improving both solution quality and diversity simultaneously.\nA system Controller coordinates interactions among all components via an asynchronous pipeline, optimized for throughput to maximize the number of candidate solutions evaluated within a given compute budget.\nAblations The ablation studies below clearly reveal each component’s contribution. On both the task of finding tensor decompositions for faster matrix multiplication and computing lower bounds on kissing numbers (sphere packing), removing any single component degrades performance:\nFig. 5. AlphaEvolve ablation results on matrix multiplication tensor decomposition and Kissing. (Image source: Novikov et al., 2025)\nSetting Modification Performance Impact Full method None Best performance No evolution Remove evolutionary search; repeatedly re-inject the same initial program Worst performance; proves evolution is the core driving mechanism No context in prompt Remove problem-specific context information Large performance drop; context is crucial to generation quality Small base LLM only Replace SOTA LLM with a smaller model Performance capped; strong reasoning models set the upper bound No full-file evolution Evolve only a single function instead of the entire codebase Noticeable drop; global cross-function co-optimization matters No meta prompt evolution Disable meta prompt evolution Moderate drop; prompt self-improvement raises the attainable ceiling Results The achievements of AlphaEvolve span two dimensions: scientific/mathematical discovery and engineering optimization:\nMathematical Discovery: Systematic experiments were conducted on over 50 open mathematical problems. AlphaEvolve matched the best-known constructions in approximately 75% of cases and surpassed prior SOTA results in roughly 20%, discovering new, provably better constructions. A representative highlight is the $4 \\times 4$ complex-valued matrix multiplication problem, where AlphaEvolve discovered a 48-scalar-multiplication algorithm, improving upon the previous best-known 49-multiplication construction for this setting. This result sits within a long lineage of algebraic optimization research dating back to seminal breakthroughs such as Strassen’s algorithm, which fundamentally reshaped our understanding of matrix multiplication complexity, and it underscores how LLM-guided evolutionary search can meaningfully advance classical algorithmic frontiers.\nEngineering Optimization: Achieved multiple scalable performance improvements within Google’s production-grade compute infrastructure. In data center scheduling, it discovered a new, interpretable heuristic function for the Borg system, continuously recovering on average 0.7% of Google’s fleet-wide stranded compute resources. In Gemini’s core training stack, by optimizing tiling heuristics for matrix multiplication kernels, it achieved an average 23% kernel speedup, directly leading to a 1% reduction in overall training time. Furthermore, it reduced the optimization process from months of dedicated expert engineering to just days of automated experimentation.\nAI for Science Recent research indicates that as LLMs’ foundational capabilities, long chain-of-thought reasoning, and agentic abilities continue to scale, they are showing unprecedented potential in scientific discovery. Advanced models represented by Gemini 3 Deep Think (DeepMind, 2026) and GPT‑5.2 (OpenAI, 2025) have significantly improved research efficiency across disciplines like mathematics, physics, and biology, accelerating the exploration of critical problems.\nAletheia Aletheia (Feng et al., 2026) is an agent for mathematical research that simulates the authentic workflow of mathematicians. Its core is an iterative Generate-Verify-Revise closed-loop mechanism, continuously optimizing solution paths and conclusion reliability through cyclic reasoning and formal verification.\nFig. 6. Overview of Aletheia, a math research agent powered by Deep Think. It iteratively generates, verifies, and revises solutions. (Image source: Luong \u0026 Mirrokni, 2026)\nGenerator: Leverages Deep Think’s long chain-of-thought reasoning to explore possible solution routes given the current problem state, proposing candidate proof steps, lemmas, or constructions. Verifier: Acts as a critical constraint component, typically implemented via fine-tuned models or formal provers, to scrutinize generated results, locate logical gaps, hallucinations, and calculation/derivation errors, outputting actionable feedback. Reviser: Updates the problem-solving trajectory based on verification feedback: patching local steps, replacing faulty lemmas, and backtracking to previous decision points to re-search when necessary, thus entering the next iteration. Fig. 7. The January 2026 Deep Think surpasses IMO-Gold on Olympiad problems, scales to PhD-level tasks, and, with Aletheia, delivers stronger reasoning at lower compute. (Image source: Feng et al., 2026)\nAs compute resources increase during the inference phase, Gemini Deep Think achieves up to a 90% score on the IMO-ProofBench, providing strong empirical support for inference-time scaling law. This law applies not only to Olympiad-level problems but also transfers to PhD-level tasks like the FutureMath Basic benchmark. Aletheia achieves higher reasoning quality with lower inference compute overhead.\nFig. 8. The work proposes a taxonomy for AI-assisted mathematics based on research significance and AI contribution, reports several Level 0–2 results with Level 2 papers submitted to journals, and currently claims no Level 3 or 4 breakthroughs. (Image source: Feng et al., 2026)\nAletheia has already produced multiple Level 2 results in frontier mathematical research, with some papers submitted to journals, alongside several autonomously completed Level 0–1 results. While it has not yet delivered a major milestone breakthrough, it demonstrates a stable capacity to produce research-grade outputs.\nFrontier Research Progress In Early Science Acceleration Experiments with GPT-5 (Bubeck et al., 2025), OpenAI showcases GPT-5’s cross-disciplinary collaboration capabilities in real research environments. The report compiles case studies spanning mathematics, physics, astronomy, computer science, biomedicine, and materials science, documenting how the model—under expert guidance—contributes to exploring and making progress on frontier problems.\nIn parallel, DeepMind’s Accelerating Scientific Research with Gemini (Woodruff et al., 2026) presents practical evidence of frontier LLMs entering theoretical research workflows as “research collaborators,” covering mathematics, theoretical computer science, physics, and economics. The models participate deeply in hypothesis generation, path searching, proof generation, and rigor checking.\nTaken together, these cases indicate that frontier LLMs are increasingly embedded into the core chain of scientific reasoning: from proposing research directions and restructuring proof strategies, to synthesizing literature in depth, identifying potential gaps, and producing research artifacts with publication-level value. More recently, GPT-5 has been integrated into automated experimental systems—closing the loop with robotic platforms to form an AI-driven autonomous laboratory that continuously iterates from hypothesis generation to physical validation.\nFig. 9. GPT-5-driven autonomous laboratory workflow. (Image source: Smith et al., 2026)\nExperimental Design Generation: GPT-5 conducts data analysis and biochemical reasoning based on historical data and literature, batch-generating experimental protocols in a 384-well plate format. Structured Validation: Experimental protocols are encoded as Pydantic objects for field, dosage, and equipment executability validation, preventing hallucinated experiments. Automated Execution: Translated into machine instructions via the Catalyst protocol, completing pipetting, incubation, and detection in the RAC system. Data Backflow Analysis: Experimental data and metadata are automatically fed back to GPT-5 for performance evaluation, hypothesis updating, and the next round of experimental design. From these theoretical and experimental cases, a reusable methodology for AI-assisted research can be distilled:\nIterative refinement: progressively correct errors, supplement hypotheses, and converge reasoning paths through multi-turn feedback, approaching rigorous conclusions incrementally. Problem decomposition: break complex open problems into verifiable sub-propositions or key computational modules, reducing the risk of single-step reasoning failures. Cross-pollination: leverage the model’s broad knowledge to map concepts across disciplines and reuse tools, unlocking new routes past proof bottlenecks. Counterexample \u0026 simulation: rapidly eliminate incorrect directions through instance generation, code-based checks, or small-scale numerical simulations. Rigor checks: expand high-level proof sketches into publication-grade arguments, systematically checking symbol consistency and logical closure. Agentic tool loops: embed models into code execution or lab automation to implement an automated “generate–execute–feedback–revise” closed loop. Overall, AI for Science appears to be shifting from assistive intelligence to collaborative intelligence, and further toward closed-loop intelligence.\nConclusion Self-evolving agents—exemplified by FunSearch, AlphaEvolve, and Aletheia—demonstrate that embedding large language models into iterative loops of generation, verification, and revision can effectively break the ceiling of one-shot reasoning. In complex search spaces such as mathematical discovery and engineering optimization, these closed-loop systems can explore and produce results that go beyond existing best-known solutions.\nAs long-horizon reasoning increasingly integrates with agentic toolchains (e.g., autonomous laboratories), Self-Evolving Agents are evolving from passive assistants into active scientific collaborators. Such closed-loop systems with high autonomy not only reshape the division of labor between humans and AI, but may also become a key driver of disruptive breakthroughs in AI for Science.\nReferences [1] Novikov, Alexander, et al. “Alphaevolve: A coding agent for scientific and algorithmic discovery.” arXiv preprint arXiv:2506.13131 (2025).\n[2] Romera-Paredes, Bernardino, et al. “Mathematical discoveries from program search with large language models.” Nature 625.7995 (2024): 468-475.\n[3] Asankhaya Sharma. OpenEvolve: Open-source implementation of AlphaEvolve. GitHub (2025).\n[4] Mouret, Jean-Baptiste, and Jeff Clune. “Illuminating search spaces by mapping elites.” arXiv preprint arXiv:1504.04909 (2015).\n[5] Verma, Abhishek, et al. “Large-scale cluster management at Google with Borg.” Proceedings of the tenth european conference on computer systems. 2015.\n[6] DeepMind. “Gemini 3 Deep Think: Advancing science, research and engineering” Google Blog (2026).\n[7] OpenAI. “Introducing GPT-5.2.” OpenAI Blog (2025).\n[8] Feng, Tony, et al. “Towards Autonomous Mathematics Research.” arXiv preprint arXiv:2602.10177 (2026).\n[9] Luong, Thang, and Vahab Mirrokni. “Accelerating mathematical and scientific discovery with Gemini Deep Think.” Google DeepMind Blog (2026).\n[10] Bubeck, Sébastien, et al. “Early science acceleration experiments with GPT-5.” arXiv preprint arXiv:2511.16072 (2025).\n[11] Woodruff, David P., et al. “Accelerating Scientific Research with Gemini: Case Studies and Common Techniques.” arXiv preprint arXiv:2602.03837 (2026).\n[12] Smith, Alexus A., et al. “Using a GPT-5-driven autonomous lab to optimize the cost and titer of cell-free protein synthesis.” bioRxiv (2026): 2026-02.\nCitation Citation: When reposting or citing content from this article, please credit the original author and source.\nCited as:\nYue Shui. (Feb 2026). Self-Evolving Agents. https://syhya.github.io/posts/2026-02-20-self-evolving-agents\nOr\n@article{syhya2026-self-evolving-agents, title = \"Self-Evolving Agents\", author = \"Yue Shui\", journal = \"syhya.github.io\", year = \"2026\", month = \"Feb\", url = \"https://syhya.github.io/posts/2026-02-20-self-evolving-agents\" } ","wordCount":"2286","inLanguage":"en","datePublished":"2026-02-20T12:00:00+08:00","dateModified":"2026-02-20T12:00:00+08:00","author":{"@type":"Person","name":"Yue Shui"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://syhya.github.io/posts/2026-02-20-self-evolving-agents/"},"publisher":{"@type":"Organization","name":"Yue Shui Blog","logo":{"@type":"ImageObject","url":"https://syhya.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://syhya.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://syhya.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://syhya.github.io/zh/ title=简体中文 aria-label=简体中文>Zh</a></li></ul></div></div><ul id=menu><li><a href=https://syhya.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://syhya.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://syhya.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://syhya.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://syhya.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Self-Evolving Agents</h1><div class=post-meta><span title='2026-02-20 12:00:00 +0800 +0800'>Created:&nbsp;2026-02-20</span>&nbsp;·&nbsp;Updated:&nbsp;2026-02-20&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2286 words&nbsp;·&nbsp;Yue Shui&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://syhya.github.io/zh/posts/2026-02-20-self-evolving-agents/>Zh</a></li></ul></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#funsearch>FunSearch</a></li><li><a href=#alphaevolve>AlphaEvolve</a><ul><li><a href=#openevolve>OpenEvolve</a></li><li><a href=#ablations>Ablations</a></li><li><a href=#results>Results</a></li></ul></li><li><a href=#ai-for-science>AI for Science</a><ul><li><a href=#aletheia>Aletheia</a></li><li><a href=#frontier-research-progress>Frontier Research Progress</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#references>References</a></li><li><a href=#citation>Citation</a></li></ul></nav></div></details></div><div class=post-content><p>A structural shift is underway in AI: the core capability of agents is moving from <strong>one-shot answer generation</strong> to continually producing verifiable, self-improving results in <strong>closed-loop systems</strong>. A representative milestone is DeepMind&rsquo;s release of <a href=https://deepmind.google/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/>AlphaEvolve</a>, an LLM-driven evolutionary coding agent that has delivered breakthroughs in mathematics, algorithm design, and engineering optimization, in several cases improving upon best-known human-designed baselines. Under this paradigm, the division of labor between humans and agents is clearly reconfigured:</p><ul><li>Humans are responsible for defining the <strong>What</strong> — setting evaluation criteria, providing initial candidate solutions, and injecting essential background knowledge as <em>context</em> into the model.</li><li>Agents are responsible for figuring out the <strong>How</strong> — autonomously searching for and discovering better structures and algorithmic implementations by generating code and invoking external tools.</li></ul><figure class=align-center><a href=alpha-evolve-high-level.png data-fancybox=gallery><img loading=lazy src=alpha-evolve-high-level.png#center alt="Fig. 1. AlphaEvolve high-level overview. (Image source: Novikov et al., 2025)" width=80%></a><figcaption><p>Fig. 1. AlphaEvolve high-level overview. (Image source: <a href=https://arxiv.org/abs/2506.13131>Novikov et al., 2025</a>)</p></figcaption></figure><h2 id=funsearch>FunSearch<a hidden class=anchor aria-hidden=true href=#funsearch>#</a></h2><p>Many LLM workflows rely on prompt engineering to elicit the desired output in a single pass, with the quality of the results largely determined by the model’s capabilities and the effectiveness of the prompt design. While highly effective for tasks like Q&amp;A and summarization, this approach has limitations in scenarios requiring the exploration of a search space or finding solutions that surpass the current state-of-the-art (SOTA). <strong>FunSearch</strong> (<a href=https://www.nature.com/articles/s41586-023-06924-6>Romera-Paredes et al., 2024</a>) emphasizes an iterative closed-loop approach, allowing the model to repeatedly generate, evaluate, and refine programs in an external environment.</p><figure class=align-center><a href=fun-search-arch.png data-fancybox=gallery><img loading=lazy src=fun-search-arch.png#center alt="Fig. 2. The overview of FunSearch. (Image source: Romera-Paredes et al., 2024)" width=90%></a><figcaption><p>Fig. 2. The overview of FunSearch. (Image source: <a href=https://www.nature.com/articles/s41586-023-06924-6>Romera-Paredes et al., 2024</a>)</p></figcaption></figure><p>FunSearch is a stateful iterative closed loop:</p>$$\text{Specification} \rightarrow \text{Program Generation} \rightarrow \text{Evaluation} \rightarrow \text{Program Database Update} \rightarrow \text{Next Iteration}$$<p>This presents three fundamental differences from the traditional single-pass generation paradigm:</p><ul><li><strong>Externally Verifiable</strong>: Evaluation scores come from real executors (code execution, mathematical verification, performance testing).</li><li><strong>Cumulative Improvement</strong>: Each iteration builds on the best solutions so far, often yielding consistent gains over time.</li><li><strong>Governable</strong>: Sandbox execution, approval mechanisms, and rule constraints can be embedded into the loop, ensuring safety and controllability.</li></ul><h2 id=alphaevolve>AlphaEvolve<a hidden class=anchor aria-hidden=true href=#alphaevolve>#</a></h2><p><strong>AlphaEvolve</strong> (<a href=https://arxiv.org/abs/2506.13131>Novikov et al., 2025</a>) is DeepMind&rsquo;s next-generation evolutionary coding agent. Its core architecture orchestrates a closed-loop pipeline: LLMs generate and modify candidate programs, evaluators provide task-specific performance signals, and an evolutionary algorithm performs selection and mutation based on those signals—iteratively optimizing within the program space.</p><figure class=align-center><a href=alpha-evolve-arch.png data-fancybox=gallery><img loading=lazy src=alpha-evolve-arch.png#center alt="Fig. 3. The overall view of the AlphaEvolve discovery process. (Image source: Novikov et al., 2025)" width=95%></a><figcaption><p>Fig. 3. The overall view of the AlphaEvolve discovery process. (Image source: <a href=https://arxiv.org/abs/2506.13131>Novikov et al., 2025</a>)</p></figcaption></figure><p>Compared to its predecessor FunSearch, which primarily focused on single-function optimization, AlphaEvolve expands the search space to entire codebases spanning multiple functions and components. Leveraging the long-context reasoning capabilities of SOTA LLMs, AlphaEvolve significantly enlarges the searchable program space, thereby raising the performance ceiling for complex algorithm discovery tasks.</p><table><thead><tr><th style=text-align:left><strong>Feature</strong></th><th style=text-align:left>FunSearch</th><th style=text-align:left>AlphaEvolve</th></tr></thead><tbody><tr><td style=text-align:left>Scope</td><td style=text-align:left>evolves single function</td><td style=text-align:left>evolves entire code file</td></tr><tr><td style=text-align:left>Size</td><td style=text-align:left>evolves up to 10-20 lines of code</td><td style=text-align:left>evolves up to hundreds of lines of code</td></tr><tr><td style=text-align:left>Language</td><td style=text-align:left>evolves code in Python</td><td style=text-align:left>evolves any language</td></tr><tr><td style=text-align:left>Evaluation</td><td style=text-align:left>needs fast evaluation (≤ 20min on 1 CPU)</td><td style=text-align:left>can evaluate for hours, in parallel, on accelerators</td></tr><tr><td style=text-align:left>LLM Samples</td><td style=text-align:left>millions of LLM samples used</td><td style=text-align:left>thousands of LLM samples suffice</td></tr><tr><td style=text-align:left>LLM Type</td><td style=text-align:left>small LLMs used; no benefit from larger</td><td style=text-align:left>benefits from SOTA LLMs</td></tr><tr><td style=text-align:left>Prompt Context</td><td style=text-align:left>minimal context (only previous solutions)</td><td style=text-align:left>rich context and feedback in prompts</td></tr><tr><td style=text-align:left>Objective</td><td style=text-align:left>optimizes single metric</td><td style=text-align:left>can simultaneously optimize multiple metrics</td></tr></tbody></table><h3 id=openevolve>OpenEvolve<a hidden class=anchor aria-hidden=true href=#openevolve>#</a></h3><p><a href=https://github.com/codelion/openevolve>OpenEvolve</a> provides a high-quality open-source engineering implementation of AlphaEvolve, fully realizing its four core modules:</p><figure class=align-center><a href=openevolve-architecture.png data-fancybox=gallery><img loading=lazy src=openevolve-architecture.png#center alt="Fig. 4. The OpenEvolve architecture: showing the integration of LLMs, MAP-Elites population database, cascade evaluator, and evolution controller. (Image source: OpenEvolve)" width=80%></a><figcaption><p>Fig. 4. The OpenEvolve architecture: showing the integration of LLMs, MAP-Elites population database, cascade evaluator, and evolution controller. (Image source: <a href=https://github.com/codelion/openevolve>OpenEvolve</a>)</p></figcaption></figure><p><strong>Prompt Sampler</strong>: Samples previously discovered solutions from the program database to construct rich context prompts. It includes not only the current best solution but also diverse sub-optimal alternatives as inspiration, preventing the LLM from falling into a single mode. Combined with a <strong>meta prompting</strong> mechanism, the LLM is used not only to generate answers but also to co-evolve the instructions and context themselves, thereby improving overall reasoning quality.</p><p><strong>LLM Ensemble</strong>: coordinates small and large models working synergistically—for example, a high-throughput smaller model handles broad exploration (increasing the rate of candidate generation), while a higher-reasoning large model focuses on occasional, high-quality rewrites. This ensemble strategy balances exploration and exploitation.</p><p><strong>Evaluator Pool</strong>: supports deterministic tests, cascaded statistical hypothesis testing, LLM-assisted feedback signals, and parallelized evaluation to improve throughput and efficiency. Evaluation results guide subsequent LLM generations, enabling continuous hill-climbing driven by error signals.</p><p><strong>Program Database</strong>: maintains a population of solutions using <strong>MAP-Elites</strong> (<a href=https://arxiv.org/abs/1504.04909>Mouret & Clune, 2015</a>) and an <a href=https://en.wikipedia.org/wiki/Population_model_(evolutionary_algorithm)>island-based population model</a>. MAP-Elites maps the solution space onto a user-defined multidimensional feature grid, retaining the highest-fitness individual in each cell—improving both solution quality and diversity simultaneously.</p><p>A system <strong>Controller</strong> coordinates interactions among all components via an asynchronous pipeline, optimized for throughput to maximize the number of candidate solutions evaluated within a given compute budget.</p><h3 id=ablations>Ablations<a hidden class=anchor aria-hidden=true href=#ablations>#</a></h3><p>The ablation studies below clearly reveal each component&rsquo;s contribution. On both the task of finding tensor decompositions for faster matrix multiplication and computing lower bounds on kissing numbers (sphere packing), removing any single component degrades performance:</p><figure class=align-center><a href=alpha-evolve-ablations.png data-fancybox=gallery><img loading=lazy src=alpha-evolve-ablations.png#center alt="Fig. 5. AlphaEvolve ablation results on matrix multiplication tensor decomposition and Kissing. (Image source: Novikov et al., 2025)" width=100%></a><figcaption><p>Fig. 5. AlphaEvolve ablation results on matrix multiplication tensor decomposition and Kissing. (Image source: <a href=https://arxiv.org/abs/2506.13131>Novikov et al., 2025</a>)</p></figcaption></figure><table><thead><tr><th style=text-align:left><strong>Setting</strong></th><th style=text-align:left>Modification</th><th style=text-align:left>Performance Impact</th></tr></thead><tbody><tr><td style=text-align:left>Full method</td><td style=text-align:left>None</td><td style=text-align:left>Best performance</td></tr><tr><td style=text-align:left>No evolution</td><td style=text-align:left>Remove evolutionary search; repeatedly re-inject the same initial program</td><td style=text-align:left>Worst performance; proves evolution is the core driving mechanism</td></tr><tr><td style=text-align:left>No context in prompt</td><td style=text-align:left>Remove problem-specific context information</td><td style=text-align:left>Large performance drop; context is crucial to generation quality</td></tr><tr><td style=text-align:left>Small base LLM only</td><td style=text-align:left>Replace SOTA LLM with a smaller model</td><td style=text-align:left>Performance capped; strong reasoning models set the upper bound</td></tr><tr><td style=text-align:left>No full-file evolution</td><td style=text-align:left>Evolve only a single function instead of the entire codebase</td><td style=text-align:left>Noticeable drop; global cross-function co-optimization matters</td></tr><tr><td style=text-align:left>No meta prompt evolution</td><td style=text-align:left>Disable meta prompt evolution</td><td style=text-align:left>Moderate drop; prompt self-improvement raises the attainable ceiling</td></tr></tbody></table><h3 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h3><p>The achievements of AlphaEvolve span two dimensions: scientific/mathematical discovery and engineering optimization:</p><p><strong>Mathematical Discovery</strong>: Systematic experiments were conducted on over 50 open mathematical problems. AlphaEvolve matched the best-known constructions in approximately 75% of cases and surpassed prior SOTA results in roughly 20%, discovering new, provably better constructions. A representative highlight is the $4 \times 4$ complex-valued matrix multiplication problem, where AlphaEvolve discovered a <strong>48-scalar-multiplication algorithm</strong>, improving upon the previous best-known 49-multiplication construction for this setting. This result sits within a long lineage of algebraic optimization research dating back to seminal breakthroughs such as <a href=https://en.wikipedia.org/wiki/Strassen_algorithm>Strassen&rsquo;s algorithm</a>, which fundamentally reshaped our understanding of matrix multiplication complexity, and it underscores how LLM-guided evolutionary search can meaningfully advance classical algorithmic frontiers.</p><p><strong>Engineering Optimization</strong>: Achieved multiple scalable performance improvements within Google&rsquo;s production-grade compute infrastructure. In data center scheduling, it discovered a new, interpretable heuristic function for the <a href=https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/>Borg system</a>, continuously recovering on average <strong>0.7% of Google&rsquo;s fleet-wide stranded compute resources</strong>. In Gemini&rsquo;s core training stack, by optimizing tiling heuristics for matrix multiplication kernels, it achieved an <strong>average 23% kernel speedup</strong>, directly leading to a <strong>1% reduction in overall training time</strong>. Furthermore, it reduced the optimization process from months of dedicated expert engineering to just days of automated experimentation.</p><h2 id=ai-for-science>AI for Science<a hidden class=anchor aria-hidden=true href=#ai-for-science>#</a></h2><p>Recent research indicates that as LLMs&rsquo; foundational capabilities, long chain-of-thought reasoning, and agentic abilities continue to scale, they are showing unprecedented potential in scientific discovery. Advanced models represented by <strong>Gemini 3 Deep Think</strong> (<a href=https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/>DeepMind, 2026</a>) and <strong>GPT‑5.2</strong> (<a href=https://openai.com/index/introducing-gpt-5-2/>OpenAI, 2025</a>) have significantly improved research efficiency across disciplines like mathematics, physics, and biology, accelerating the exploration of critical problems.</p><h3 id=aletheia>Aletheia<a hidden class=anchor aria-hidden=true href=#aletheia>#</a></h3><p><strong>Aletheia</strong> (<a href=https://arxiv.org/abs/2602.10177>Feng et al., 2026</a>) is an agent for mathematical research that simulates the authentic workflow of mathematicians. Its core is an iterative <strong>Generate-Verify-Revise</strong> closed-loop mechanism, continuously optimizing solution paths and conclusion reliability through cyclic reasoning and formal verification.</p><figure class=align-center><a href=aletheia_overview.png data-fancybox=gallery><img loading=lazy src=aletheia_overview.png#center alt="Fig. 6. Overview of Aletheia, a math research agent powered by Deep Think. It iteratively generates, verifies, and revises solutions. (Image source: Luong & Mirrokni, 2026)" width=100%></a><figcaption><p>Fig. 6. Overview of Aletheia, a math research agent powered by Deep Think. It iteratively generates, verifies, and revises solutions. (Image source: <a href=https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/>Luong & Mirrokni, 2026</a>)</p></figcaption></figure><ol><li><strong>Generator</strong>: Leverages Deep Think&rsquo;s long chain-of-thought reasoning to explore possible solution routes given the current problem state, proposing candidate proof steps, lemmas, or constructions.</li><li><strong>Verifier</strong>: Acts as a critical constraint component, typically implemented via fine-tuned models or formal provers, to scrutinize generated results, locate logical gaps, hallucinations, and calculation/derivation errors, outputting actionable feedback.</li><li><strong>Reviser</strong>: Updates the problem-solving trajectory based on verification feedback: patching local steps, replacing faulty lemmas, and backtracking to previous decision points to re-search when necessary, thus entering the next iteration.</li></ol><figure class=align-center><a href=aletheia_eval_res.png data-fancybox=gallery><img loading=lazy src=aletheia_eval_res.png#center alt="Fig. 7. The January 2026 Deep Think surpasses IMO-Gold on Olympiad problems, scales to PhD-level tasks, and, with Aletheia, delivers stronger reasoning at lower compute. (Image source: Feng et al., 2026)" width=100%></a><figcaption><p>Fig. 7. The January 2026 Deep Think surpasses IMO-Gold on Olympiad problems, scales to PhD-level tasks, and, with Aletheia, delivers stronger reasoning at lower compute. (Image source: <a href=https://arxiv.org/abs/2602.10177>Feng et al., 2026</a>)</p></figcaption></figure><p>As compute resources increase during the inference phase, Gemini Deep Think achieves up to a 90% score on the <a href=https://imobench.github.io/>IMO-ProofBench</a>, providing strong empirical support for <a href=https://syhya.github.io/posts/2025-11-19-scaling-law/#test-time-scaling>inference-time scaling law</a>. This law applies not only to Olympiad-level problems but also transfers to PhD-level tasks like the FutureMath Basic benchmark. Aletheia achieves higher reasoning quality with lower inference compute overhead.</p><figure class=align-center><a href=aletheia_research_output.png data-fancybox=gallery><img loading=lazy src=aletheia_research_output.png#center alt="Fig. 8. The work proposes a taxonomy for AI-assisted mathematics based on research significance and AI contribution, reports several Level 0–2 results with Level 2 papers submitted to journals, and currently claims no Level 3 or 4 breakthroughs. (Image source: Feng et al., 2026)" width=100%></a><figcaption><p>Fig. 8. The work proposes a taxonomy for AI-assisted mathematics based on research significance and AI contribution, reports several Level 0–2 results with Level 2 papers submitted to journals, and currently claims no Level 3 or 4 breakthroughs. (Image source: <a href=https://arxiv.org/abs/2602.10177>Feng et al., 2026</a>)</p></figcaption></figure><p>Aletheia has already produced multiple <strong>Level 2</strong> results in frontier mathematical research, with some papers submitted to journals, alongside several autonomously completed <strong>Level 0–1</strong> results. While it has not yet delivered a major milestone breakthrough, it demonstrates a stable capacity to produce research-grade outputs.</p><h3 id=frontier-research-progress>Frontier Research Progress<a hidden class=anchor aria-hidden=true href=#frontier-research-progress>#</a></h3><p>In <strong>Early Science Acceleration Experiments with GPT-5</strong> (<a href=https://arxiv.org/abs/2511.16072>Bubeck et al., 2025</a>), OpenAI showcases GPT-5&rsquo;s cross-disciplinary collaboration capabilities in real research environments. The report compiles case studies spanning mathematics, physics, astronomy, computer science, biomedicine, and materials science, documenting how the model—under expert guidance—contributes to exploring and making progress on frontier problems.</p><p>In parallel, DeepMind&rsquo;s <strong>Accelerating Scientific Research with Gemini</strong> (<a href=https://arxiv.org/abs/2602.03837>Woodruff et al., 2026</a>) presents practical evidence of frontier LLMs entering theoretical research workflows as &ldquo;research collaborators,&rdquo; covering mathematics, theoretical computer science, physics, and economics. The models participate deeply in hypothesis generation, path searching, proof generation, and rigor checking.</p><p>Taken together, these cases indicate that frontier LLMs are increasingly embedded into the core chain of scientific reasoning: from proposing research directions and restructuring proof strategies, to synthesizing literature in depth, identifying potential gaps, and producing research artifacts with publication-level value. More recently, GPT-5 has been integrated into automated experimental systems—closing the loop with robotic platforms to form an <strong>AI-driven autonomous laboratory</strong> that continuously iterates from hypothesis generation to physical validation.</p><figure class=align-center><a href=gpt5_driven_auto_lab.png data-fancybox=gallery><img loading=lazy src=gpt5_driven_auto_lab.png#center alt="Fig. 9. GPT-5-driven autonomous laboratory workflow. (Image source: Smith et al., 2026)" width=100%></a><figcaption><p>Fig. 9. GPT-5-driven autonomous laboratory workflow. (Image source: <a href=https://www.biorxiv.org/content/10.64898/2026.02.05.703998v1>Smith et al., 2026</a>)</p></figcaption></figure><ul><li><strong>Experimental Design Generation</strong>: GPT-5 conducts data analysis and biochemical reasoning based on historical data and literature, batch-generating experimental protocols in a 384-well plate format.</li><li><strong>Structured Validation</strong>: Experimental protocols are encoded as Pydantic objects for field, dosage, and equipment executability validation, preventing hallucinated experiments.</li><li><strong>Automated Execution</strong>: Translated into machine instructions via the Catalyst protocol, completing pipetting, incubation, and detection in the RAC system.</li><li><strong>Data Backflow Analysis</strong>: Experimental data and metadata are automatically fed back to GPT-5 for performance evaluation, hypothesis updating, and the next round of experimental design.</li></ul><p>From these theoretical and experimental cases, a reusable methodology for AI-assisted research can be distilled:</p><ul><li><strong>Iterative refinement</strong>: progressively correct errors, supplement hypotheses, and converge reasoning paths through multi-turn feedback, approaching rigorous conclusions incrementally.</li><li><strong>Problem decomposition</strong>: break complex open problems into verifiable sub-propositions or key computational modules, reducing the risk of single-step reasoning failures.</li><li><strong>Cross-pollination</strong>: leverage the model&rsquo;s broad knowledge to map concepts across disciplines and reuse tools, unlocking new routes past proof bottlenecks.</li><li><strong>Counterexample & simulation</strong>: rapidly eliminate incorrect directions through instance generation, code-based checks, or small-scale numerical simulations.</li><li><strong>Rigor checks</strong>: expand high-level proof sketches into publication-grade arguments, systematically checking symbol consistency and logical closure.</li><li><strong>Agentic tool loops</strong>: embed models into code execution or lab automation to implement an automated &ldquo;generate–execute–feedback–revise&rdquo; closed loop.</li></ul><p>Overall, <em>AI for Science</em> appears to be shifting from assistive intelligence to collaborative intelligence, and further toward <strong>closed-loop intelligence</strong>.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Self-evolving agents—exemplified by FunSearch, AlphaEvolve, and Aletheia—demonstrate that embedding large language models into iterative loops of <strong>generation, verification, and revision</strong> can effectively break the ceiling of one-shot reasoning. In complex search spaces such as mathematical discovery and engineering optimization, these closed-loop systems can explore and produce results that go beyond existing best-known solutions.</p><p>As long-horizon reasoning increasingly integrates with agentic toolchains (e.g., autonomous laboratories), <strong>Self-Evolving Agents</strong> are evolving from passive assistants into active scientific collaborators. Such closed-loop systems with high autonomy not only reshape the division of labor between humans and AI, but may also become a key driver of disruptive breakthroughs in AI for Science.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] Novikov, Alexander, et al. <a href=https://arxiv.org/abs/2506.13131>&ldquo;Alphaevolve: A coding agent for scientific and algorithmic discovery.&rdquo;</a> arXiv preprint arXiv:2506.13131 (2025).</p><p>[2] Romera-Paredes, Bernardino, et al. <a href=https://www.nature.com/articles/s41586-023-06924-6>&ldquo;Mathematical discoveries from program search with large language models.&rdquo;</a> Nature 625.7995 (2024): 468-475.</p><p>[3] Asankhaya Sharma. <a href=https://github.com/codelion/openevolve>OpenEvolve: Open-source implementation of AlphaEvolve</a>. GitHub (2025).</p><p>[4] Mouret, Jean-Baptiste, and Jeff Clune. <a href=https://arxiv.org/abs/1504.04909>&ldquo;Illuminating search spaces by mapping elites.&rdquo;</a> arXiv preprint arXiv:1504.04909 (2015).</p><p>[5] Verma, Abhishek, et al. <a href=https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/>&ldquo;Large-scale cluster management at Google with Borg.&rdquo;</a> Proceedings of the tenth european conference on computer systems. 2015.</p><p>[6] DeepMind. <a href=https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/>&ldquo;Gemini 3 Deep Think: Advancing science, research and engineering&rdquo;</a> Google Blog (2026).</p><p>[7] OpenAI. <a href=https://openai.com/index/introducing-gpt-5-2/>&ldquo;Introducing GPT-5.2.&rdquo;</a> OpenAI Blog (2025).</p><p>[8] Feng, Tony, et al. <a href=https://arxiv.org/abs/2602.10177>&ldquo;Towards Autonomous Mathematics Research.&rdquo;</a> arXiv preprint arXiv:2602.10177 (2026).</p><p>[9] Luong, Thang, and Vahab Mirrokni. <a href=https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/>&ldquo;Accelerating mathematical and scientific discovery with Gemini Deep Think.&rdquo;</a> Google DeepMind Blog (2026).</p><p>[10] Bubeck, Sébastien, et al. <a href=https://arxiv.org/abs/2511.16072>&ldquo;Early science acceleration experiments with GPT-5.&rdquo;</a> arXiv preprint arXiv:2511.16072 (2025).</p><p>[11] Woodruff, David P., et al. <a href=https://arxiv.org/abs/2602.03837>&ldquo;Accelerating Scientific Research with Gemini: Case Studies and Common Techniques.&rdquo;</a> arXiv preprint arXiv:2602.03837 (2026).</p><p>[12] Smith, Alexus A., et al. <a href=https://www.biorxiv.org/content/10.64898/2026.02.05.703998v1>&ldquo;Using a GPT-5-driven autonomous lab to optimize the cost and titer of cell-free protein synthesis.&rdquo;</a> bioRxiv (2026): 2026-02.</p><h2 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h2><blockquote><p><strong>Citation</strong>: When reposting or citing content from this article, please credit the original author and source.</p></blockquote><p><strong>Cited as:</strong></p><blockquote><p>Yue Shui. (Feb 2026). Self-Evolving Agents.
<a href=https://syhya.github.io/posts/2026-02-20-self-evolving-agents>https://syhya.github.io/posts/2026-02-20-self-evolving-agents</a></p></blockquote><p>Or</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bibtex data-lang=bibtex><span class=line><span class=cl><span class=nc>@article</span><span class=p>{</span><span class=nl>syhya2026-self-evolving-agents</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>title</span>   <span class=p>=</span> <span class=s>&#34;Self-Evolving Agents&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>author</span>  <span class=p>=</span> <span class=s>&#34;Yue Shui&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>journal</span> <span class=p>=</span> <span class=s>&#34;syhya.github.io&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>year</span>    <span class=p>=</span> <span class=s>&#34;2026&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>month</span>   <span class=p>=</span> <span class=s>&#34;Feb&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>url</span>     <span class=p>=</span> <span class=s>&#34;https://syhya.github.io/posts/2026-02-20-self-evolving-agents&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://syhya.github.io/tags/agent-evolve/>Agent Evolve</a></li><li><a href=https://syhya.github.io/tags/alphaevolve/>AlphaEvolve</a></li><li><a href=https://syhya.github.io/tags/openevolve/>OpenEvolve</a></li><li><a href=https://syhya.github.io/tags/ai-for-science/>AI for Science</a></li></ul><nav class=paginav><a class=next href=https://syhya.github.io/posts/2025-12-31-deepseekv3.2/><span class=title>Next »</span><br><span>DeepSeek-V3.2 Series</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Evolving Agents on x" href="https://x.com/intent/tweet/?text=Self-Evolving%20Agents&amp;url=https%3a%2f%2fsyhya.github.io%2fposts%2f2026-02-20-self-evolving-agents%2f&amp;hashtags=AgentEvolve%2cAlphaEvolve%2cOpenEvolve%2cAIforScience"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Evolving Agents on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsyhya.github.io%2fposts%2f2026-02-20-self-evolving-agents%2f&amp;title=Self-Evolving%20Agents&amp;summary=Self-Evolving%20Agents&amp;source=https%3a%2f%2fsyhya.github.io%2fposts%2f2026-02-20-self-evolving-agents%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Evolving Agents on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsyhya.github.io%2fposts%2f2026-02-20-self-evolving-agents%2f&title=Self-Evolving%20Agents"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Evolving Agents on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsyhya.github.io%2fposts%2f2026-02-20-self-evolving-agents%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Evolving Agents on whatsapp" href="https://api.whatsapp.com/send?text=Self-Evolving%20Agents%20-%20https%3a%2f%2fsyhya.github.io%2fposts%2f2026-02-20-self-evolving-agents%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Evolving Agents on telegram" href="https://telegram.me/share/url?text=Self-Evolving%20Agents&amp;url=https%3a%2f%2fsyhya.github.io%2fposts%2f2026-02-20-self-evolving-agents%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Evolving Agents on ycombinator" href="https://news.ycombinator.com/submitlink?t=Self-Evolving%20Agents&u=https%3a%2f%2fsyhya.github.io%2fposts%2f2026-02-20-self-evolving-agents%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://syhya.github.io/>Yue Shui Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>